import OpenAI from "openai";
import { getRoomMessages, type MembersMessage } from "@/lib/membersApi";
import { extractListInfo } from "@/lib/chatExtract";
import fs from "node:fs/promises";
import path from "node:path";

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

async function readPdfTextFromPublic(relativePath?: string): Promise<string> {
  if (!relativePath) return "";
  try {
    const p = path.join(process.cwd(), "public", relativePath.replace(/^\/+/, ""));
    await fs.access(p);
    const buf = await fs.readFile(p);
    const pdf = (await import("pdf-parse")).default as (b: Buffer | Uint8Array) => Promise<{ text: string }>;
    const out = await pdf(buf);
    return out.text || "";
  } catch {
    return "";
  }
}

async function readTextFromPublic(relativePath: string): Promise<string> {
  try {
    const p = path.join(process.cwd(), "public", relativePath.replace(/^\/+/, ""));
    await fs.access(p);
    const raw = await fs.readFile(p, "utf8");
    // Keep reasonable size to avoid context overflow
    return raw.length > 60000 ? raw.slice(0, 60000) + "\n...(truncated)" : raw;
  } catch {
    return "";
  }
}

async function readCsvTextsFromPublic(pathsCsv?: string): Promise<{ filename: string; text: string }[]> {
  if (!pathsCsv) return [];
  const items: { filename: string; text: string }[] = [];
  const parts = pathsCsv.split(",").map((s) => s.trim()).filter(Boolean);
  for (const rel of parts) {
    const text = await readTextFromPublic(rel);
    if (text) items.push({ filename: rel, text });
  }
  return items;
}

export interface GenerateOptions {
  roomId: number;
  force?: 0 | 1;
  useReasoning?: boolean;
  modelOverride?: string;
  targetMessageId?: number; // ç‰¹å®šã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸IDã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«ã™ã‚‹å ´åˆ
}

export interface GenerateResult {
  content: string;
  model: string;
  mode: "reasoning" | "chat";
  messages: MembersMessage[];
}

export async function generateSalesScriptFromContext(opts: GenerateOptions): Promise<GenerateResult> {
  const messages = await getRoomMessages(opts.roomId, { force: opts.force ?? 1 });
  
  // ç‰¹å®šã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸IDãŒã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®å ´åˆã€ãã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã¿ã‚’ä½¿ç”¨
  let targetMessages = messages;
  let contextInfo = "";
  
  if (opts.targetMessageId) {
    const targetMessage = messages.find(m => m.message_id === opts.targetMessageId);
    if (targetMessage) {
      // ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã¿ã‚’ä½¿ç”¨
      targetMessages = [targetMessage];
      contextInfo = `ç‰¹å®šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸(ID: ${opts.targetMessageId})`;
    } else {
      throw new Error(`Target message ID ${opts.targetMessageId} not found`);
    }
  } else {
    // å¾“æ¥é€šã‚Šæœ€æ–°50ä»¶ã‚’ä½¿ç”¨
    targetMessages = messages.slice(-50);
    contextInfo = `æœ€æ–°${targetMessages.length}ä»¶ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸`;
  }
  
  const recent = targetMessages.map((m) => `- ${m.account?.name ?? ""}: ${m.body.replace(/<[^>]+>/g, " ")}`).join("\n");
  
  // ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸IDæƒ…å ±ã‚’å–å¾—
  const messageIds = targetMessages.map(m => m.message_id);
  const latestMessageId = targetMessages.length > 0 ? targetMessages[targetMessages.length - 1].message_id : null;
  const messageCount = targetMessages.length;

  // PDFã¯ä½¿ç”¨ã—ãªã„
  const plotsPdf = "";
  const qaPdf = "";

  // æŒ‡å®šã•ã‚ŒãŸMarkdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
  let talkScriptMd = await readTextFromPublic("tesc_talk_script.md");
  
  // ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰å‘¼ã³å‡ºã—éƒ¨ç½²ã‚’æŠ½å‡º
  const listInfo = extractListInfo(messages);
  const callDepartment = listInfo.callDepartment;
  
  console.log(`[GENERATOR] æŠ½å‡ºã•ã‚ŒãŸãƒªã‚¹ãƒˆæƒ…å ±:`, {
    callDepartment: callDepartment,
    area: listInfo.area,
    extractionCondition: listInfo.extractionCondition
  });
  
  // ã€Šâ–³â–³ã€‹ã‚’å‘¼ã³å‡ºã—éƒ¨ç½²ã«ç½®æ›ï¼ˆå‘¼ã³å‡ºã—éƒ¨ç½²ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿ï¼‰
  if (talkScriptMd && callDepartment) {
    talkScriptMd = talkScriptMd.replace(/ã€Šâ–³â–³ã€‹/g, callDepartment);
    console.log(`[GENERATOR] å‘¼ã³å‡ºã—éƒ¨ç½²ã€Œ${callDepartment}ã€ã‚’ã€Šâ–³â–³ã€‹ã«é©ç”¨ã—ã¾ã—ãŸ`);
  } else {
    console.log(`[GENERATOR] å‘¼ã³å‡ºã—éƒ¨ç½²ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ç½®æ›ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸ`);
  }
  
  const mdSection = talkScriptMd
    ? `\nã€å‚è€ƒè³‡æ–™ï¼ˆå–¶æ¥­ãƒˆãƒ¼ã‚¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚¬ã‚¤ãƒ‰ï¼‰ã€‘\n${talkScriptMd}\n`
    : "";
  
  // ä»¥å‰ã®CSVèª­ã¿è¾¼ã¿ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆï¼‰
  // const csvs = await readCsvTextsFromPublic("tesc_talk_script.csv");
  // const csvSection = csvs.length
  //   ? `\nã€å‚è€ƒè³‡æ–™ï¼ˆCSVï¼‰ã€‘\n` + csvs.map((c) => `- ${c.filename}:\n${c.text}`).join("\n\n")
  //   : "";

  // prompt_for_chatgpt.txtã®å†…å®¹ã‚’èª­ã¿è¾¼ã‚“ã§ãƒ™ãƒ¼ã‚¹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ã™ã‚‹
  const basePrompt = await readTextFromPublic("prompt_for_chatgpt.txt");

  // ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã¨Markdownãƒ‡ãƒ¼ã‚¿ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å«ã‚ã‚‹
  const instruction = `${basePrompt}\n\nã€ãƒãƒ£ãƒƒãƒˆæŠœç²‹ã€‘\n${recent}${mdSection}`;

  const model = opts.modelOverride || (process.env.OPENAI_MODEL || (opts.useReasoning ? "o4-mini" : "gpt-4o-mini"));

  // APIå‘¼ã³å‡ºã—å›æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆï¼ˆç°¡æ˜“çš„ã«ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§è­˜åˆ¥ï¼‰
  const callId = Date.now();
  console.log(`[OPENAI-${callId}] ğŸ“¤ ChatGPT API å‘¼ã³å‡ºã—é–‹å§‹`);
  console.log(`[OPENAI-${callId}] Room: ${opts.roomId}, Model: ${model}, Mode: ${opts.useReasoning ? "reasoning" : "chat"}`);
  console.log(`[OPENAI-${callId}] ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: ${contextInfo}`);
  console.log(`[OPENAI-${callId}] ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°: ${messageCount}, æœ€æ–°ID: ${latestMessageId}`);
  console.log(`[OPENAI-${callId}] å«ã¾ã‚Œã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ID: [${messageIds.join(', ')}]`);
  console.log(`[OPENAI-${callId}] ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ–‡å­—æ•°: ${instruction.length}`);
  console.log(`[OPENAI-${callId}] ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†’é ­: ${instruction.substring(0, 200)}...`);

  if (opts.useReasoning) {
    console.log(`[OPENAI-${callId}] é€ä¿¡ä¸­... (reasoning mode)`);
    const resp = await openai.responses.create({
      model,
      reasoning: { effort: "medium" },
      instructions: "å–¶æ¥­ãƒˆãƒ¼ã‚¯å°æœ¬ã®ä½“è£ã‚’å³æ ¼ã«å®ˆã£ã¦ãã ã•ã„ã€‚",
      input: instruction,
    });
    const content = resp.output_text || "";
    console.log(`[OPENAI-${callId}] ğŸ“¥ ãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡å®Œäº†`);
    console.log(`[OPENAI-${callId}] è¿”å´æ–‡å­—æ•°: ${content.length}`);
    console.log(`[OPENAI-${callId}] è¿”å´å†…å®¹å†’é ­: ${content.substring(0, 300)}...`);
    return { content, model, mode: "reasoning", messages: targetMessages };
  }

  console.log(`[OPENAI-${callId}] é€ä¿¡ä¸­... (chat mode)`);
  const completion = await openai.chat.completions.create({
    model,
    messages: [
      { role: "system", content: "å–¶æ¥­ãƒˆãƒ¼ã‚¯å°æœ¬ã®ä½“è£ã‚’å³æ ¼ã«å®ˆã£ã¦ãã ã•ã„ã€‚" },
      { role: "user", content: instruction },
    ],
    temperature: 0.7,
  });
  const content = completion.choices?.[0]?.message?.content ?? "";
  console.log(`[OPENAI-${callId}] ğŸ“¥ ãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡å®Œäº†`);
  console.log(`[OPENAI-${callId}] è¿”å´æ–‡å­—æ•°: ${content.length}`);
  console.log(`[OPENAI-${callId}] è¿”å´å†…å®¹å†’é ­: ${content.substring(0, 300)}...`);
  console.log(`[OPENAI-${callId}] Usage: prompt_tokens=${completion.usage?.prompt_tokens}, completion_tokens=${completion.usage?.completion_tokens}`);
  return { content, model, mode: "chat", messages: targetMessages };
} 